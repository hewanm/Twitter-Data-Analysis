{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e863754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import STOPWORDS,WordCloud\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import string\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f536b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader class\n",
    "class DataLoader:\n",
    "    def __init__(self, dir_name, file_name):\n",
    "        self.dir_name= dir_name\n",
    "        self.file_name = file_name\n",
    "        \n",
    "\n",
    "#read data\n",
    "    def read_csv(self):\n",
    "        os.chdir(self.dir_name)\n",
    "        tweets_df= pd.read_csv(self.file_name)\n",
    "        return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff24545",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (Temp/ipykernel_20288/2377112510.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\HEWANM~1\\AppData\\Local\\Temp/ipykernel_20288/2377112510.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    DataLoader_obj = DataLoader('C:\\Users\\Hewan M\\Twitter-Data-Analysis','processed_tweet_data.csv')\u001b[0m\n\u001b[1;37m                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "DataLoader_obj = DataLoader('C:\\Users\\Hewan M\\Twitter-Data-Analysis','processed_tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436b26d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader_obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HEWANM~1\\AppData\\Local\\Temp/ipykernel_20288/4142093239.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweets_df\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataLoader_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataLoader_obj' is not defined"
     ]
    }
   ],
   "source": [
    "tweets_df= DataLoader.read_csv(DataLoader_obj)\n",
    "\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46348a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = text.replace('rt', \"\", 1)\n",
    "    return text\n",
    "\n",
    "ctext = lambda item: clean_text(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6396b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(self):\n",
    "    \n",
    "   \n",
    "    tweets_df['original_text']=tweets_df['original_text'].astype(str)\n",
    "    tweets_df['clean_text']= tweets_df['original_text'].apply(ctext)\n",
    "    tweets_df['clean_text']= tweets_df['clean_text'].apply(lambda x: x.translate(str.maketrans(' ', ' ', string.punctuation)))\n",
    "    \n",
    "    #Converting tweets to list of words For feature engineering\n",
    "    sentence_list = [tweet for tweet in tweets_df['clean_text']]\n",
    "    word_list = [sent.split() for sent in sentence_list]\n",
    "     #Create dictionary which contains Id and word \n",
    "    word_to_id = corpora.Dictionary(word_list)\n",
    "    corpus_1= [word_to_id.doc2bow(tweet) for tweet in word_list]\n",
    "    return word_list, word_to_id, corpus_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10483fe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HEWANM~1\\AppData\\Local\\Temp/ipykernel_20288/3339674371.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets_df' is not defined"
     ]
    }
   ],
   "source": [
    "preprocess_data(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e671feb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HEWANM~1\\AppData\\Local\\Temp/ipykernel_20288/24679384.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#It's a measure of how good the model is. The lower the better. Perplexity is a negative value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nPerplexity: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdoc_lda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# compute Preplexity\n",
    "\n",
    "#It's a measure of how good the model is. The lower the better. Perplexity is a negative value\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "doc_lda = lda_model[corpus]\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\n Ldamodel Coherence Score/Accuracy on Tweets: ', coherence_lda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb0514cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: numexpr in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.0.1)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.24.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.7.1)\n",
      "Collecting funcy\n",
      "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (58.0.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (6.0.0)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (0.29.23)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->pyLDAvis) (2.2.0)\n",
      "Building wheels for collected packages: pyLDAvis, sklearn\n",
      "  Building wheel for pyLDAvis (PEP 517): started\n",
      "  Building wheel for pyLDAvis (PEP 517): finished with status 'done'\n",
      "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136900 sha256=a2ded3216839c03097eb2ae2c6746203835a1874371ad184b85c03325c4d03e9\n",
      "  Stored in directory: c:\\users\\hewan m\\appdata\\local\\pip\\cache\\wheels\\57\\a4\\86\\d10c6c2e0bf149fbc0afb0aa5a6528ac35b30a133a0270c477\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=ec62b519841283d4f72401d9b0213044ec36f0859e96b12ea2528db56d1c23e1\n",
      "  Stored in directory: c:\\users\\hewan m\\appdata\\local\\pip\\cache\\wheels\\e4\\7b\\98\\b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built pyLDAvis sklearn\n",
      "Installing collected packages: sklearn, funcy, pyLDAvis\n",
      "Successfully installed funcy-1.17 pyLDAvis-3.3.1 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498daf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bfa7ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the topics\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba170d13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HEWANM~1\\AppData\\Local\\Temp/ipykernel_20288/1770614485.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLDAvis_prepared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensimvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mLDAvis_prepared\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4a58a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
